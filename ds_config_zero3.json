{
  "train_batch_size": 8,
  "gradient_accumulation_steps": 1,
  "optimizer": { "type": "AdamW", "params": { "lr": 0.0002 } },
  "zero_optimization": {
    "stage": 3,
    "overlap_comm": true,
    "contiguous_gradients": true,
    "reduce_bucket_size": 200000000,
    "stage3_prefetch_bucket_size": 50000000,
    "stage3_param_persistence_threshold": 100000,
    "gather_fp16_weights_on_model_save": true
  }
}
