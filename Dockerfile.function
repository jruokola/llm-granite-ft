# ────────────────────────────────────────────────────────────────────────────
# GPU-ready HuggingFace stack + PEFT + FSDP + 4-bit QLoRA + LoRA + AMP fine-tuning script
# ────────────────────────────────────────────────────────────────────────────
FROM nvcr.io/nvidia/pytorch:24.07-py3

# 1 — Basic runtime hygiene
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    TRANSFORMERS_NO_ADVISORY_WARNINGS=1

WORKDIR /workspace

# --- System build tools ------------------------------------------------------
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        build-essential cmake && \
    rm -rf /var/lib/apt/lists/*

# 2 — Bring pip tooling and libraries to the versions you need
#     NOTE: `transformers` is already in the base image; we add the rest.
RUN python3 -m pip install --upgrade pip setuptools wheel && \
    python3 -m pip install \
        peft \
        datasets \
        transformers \
        huggingface_hub[hf_xet] \
        accelerate \
        bitsandbytes \
        transformer_engine \
        contextlib

# 4 — Copy training code and data
COPY fixed-scripts/function-finetune-fixed.py .
COPY ./glaive_fc_v2 /processed_datasets/glaive_fc_v2/

# 5 — No CMD: I nvoke with torchrun / sbatch